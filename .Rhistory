ggplot(mtcars, aes(x=cyl, y=mpg, colour=am)) + geom_point() +theme_economist(base_size=5)
ggplot(mtcars, aes(x=cyl, y=am, colour=mpg)) + geom_point() +theme_economist(base_size=5)
ggplot(mtcars, aes(x=cyl, y=am, colour=mpg)) + geom_point() +theme_economist(base_size=20)
ggplot(mtcars, aes(x=cyl, y=am, colour=mpg)) + geom_point() +theme_economist(base_size=5)
?corr
?correlation
?cor
cor(mtcars$am, mtcars$cyl)
cor(mtcars$am, mtcars$mpg)
cor(mtcars$am, mtcars$wt)
?step
step(lm(mpg~., data=mtcars), direction="both")
qplot(mpg ~., data=mtcars)
qplot(mpg ~, data=mtcars)
plot(mtcars)
?step
bestFit <- step(lm(mpg~.,data=mtcars), direction="both")
summary(bestFit)
coef(summary(bestFit))
?mtcars
cor(mtcars$qsec, mtcars$hp)
fit1 <- lm(mpg ~ factor(am), data=mtcars);
fit2 <- lm(mpg ~ factor(am)+wt, data=mtcars);
fit3 <- lm(mpg ~ factor(am)+wt+qsec, data=mtcars);
anova(fit1,fit2,fit3)
fit <- lm(mpg ~ factor(am)+qsec+wt, data=mtcars);
summary(fit)
dfbetas(fit)
dfbetas(fit)[,4]
max(dfbetas(fit)[,4])
fit
summary(fit)
sumCoef <- summary(fit)$coefficients; sumCoef[2,1] + c(1,-1)*qt(0.975,df=fit$df)*sumCoef[2,2]
sumCoef <- summary(fit)$coefficients; sumCoef[2,1] + c(-1,1)*qt(0.975,df=fit$df)*sumCoef[2,2]
g0 <- ggplot(mtcars, aes(x=factor(am), y=mpg)) + geom_boxplot() + theme_economist(base_size=5) +xlab("Transmission") +  ylab("Miles Per Gallon") +  ggtitle("Transmission versus miles per gallon")
bestFit <- step(lm(mpg~.,data=mtcars), direction="both");
?step
bestFit <- step(lm(mpg~.,data=mtcars), direction="both", trace=0);
?mtcars
library(swirl)
swirl()
install_from_swirl("Regression Models")
swirl()
install_from_swirl("Regression Models")
swirl()
plot(child~parent, galton)
plot(jitter(child,4) ~ parent, galton)
regrline <- lm(child~parent, galton)
abline(regrline, lwd=3, col='red')
summary(regrline)
lm(child~parent, galton)
fit <- lm(child~parent, galton)
summary(fit)
mean(fit$residuals)
cov(fit$residuals, galton$parent)
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
lhs - rhs
all.equal(lhs,rhs)
varchild <- var(galton$child)
varChild <- var(galton$child)
varRes <- var(fit$residuals)
varEst <- var(est(ols.slope, ols.ic))
all.equal(varChild, varRes + varEst)
efit <- lm(accel ~mag+dist, attenu)
mean(efit$residuals)
cov(efit$residuals,attenu$mag)
cov(efit$residuals, attenu$dist)
cor(galton$parent, galton$child)
cor(gpa_nor, gch_nor)
l_nor <- lm(galton$child ~galton$parent)
l_nor <- lm(gch_nor ~gpa_nor)
fit <- lm(child ~parent, galton)
sqrt(sum(fit$residuals))
sqrt(sum(fit$residuals^2)/(n-2))
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
mu <- mean(galton$child)
sTot <- sum((galton$child - mu)^2)
sRes <- deviance(galton$child - predict(fit))
sRes <- deviance(galton$child )
sRes <- deviance(galton$child )
sRes <- (galton$child )
sRes <- deviance(fit)
1-sRes/sTot
summary(fit)$r.squared
cor(galton$child, galton$parent)^2
ones <- rep(1,nrow(galton))
lm(child~ones+parent -1)
lm(child~ones+parent -1,galton)
lm(child~parent, galton)
lm(child ~ 1, galton)
head(trees)
fit <- lm(Volume ~Girth + Height + Constant -1, trees)
trees2 <- eliminate("Girth", trees)
head(trees2)
fit2 <- lm(Volume ~Height + Constant-1,trees2)
lapply(list(fit,fit2)coef)
lapply(list(fit,fit2),coef)
library(plyr)
dd<-data.frame(matrix(rnorm(216),72,3),c(rep("A",24),rep("B",24),rep("C",24)),c(rep("J",36),rep("K",36)))
colnames(dd) <- c("v1", "v2", "v3", "dim1", "dim2")
dd
head(dd)
?ddply
df
?df
ddply(dd, c("dim1","dim2"), function(df)mean(df$v1))
ddply(dd, c("dim1","dim2"), function(df)
)
function(df)mean(c(0,2,3))
dfmean(c(0,2,3))
??ddply
?ddply
library(nycflights13)
dim(flights)
library(dplyr)
library(nycflights13)
?nycflights13
dim(nycflights13)
load(nycflights13)
load(spam)
library(spam)
library(kernlab)
install.packages(kernlab)
install.packages('kernlab')
library('kernlab')
load(spam)
spam
data(spam)
head(spam)
install.packages('caret')
install.packages('car')
install.packages('nloptr')
install.packages('caret')
install.packages("http://cran.r-project.org/src/contrib/Archive/nloptr/nloptr_1.0.0.tar.gz", repos=NULL, type="source")
install.packages('caret')
install.packages('nloptr')
install.packages('caret')
install.packages('caret')
remove.packages(nloptr)
remove.packages('nloptr')
library('caret')
library('kernlab')
library('ISLR')
install.packages('ISLR')
library('ISLR')
data(Wage)
summary(Wage)
intrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]
training <- Wage[intrain,]
test <- Wage[-intrain,]
featurePlot(x=training)
data(spam)
modFit <- train(wage ~age+jobclass+education, method="lm", data=training)
print(modFit)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages('AppliedPredictiveModeling')
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
head(adData)
head(diagnosis)
head(predictors)
head(AlzheimerDisease)
head(diagnosis)
diagnosis
head(predictors)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
head(testing)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
data(concrete)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(CompressiveStrength,SuperPlasticizer, data=training, geom="histogram")
names(training)
qplot(CompressiveStrength,Superplasticizer, data=training, geom="histogram")
qplot(Superplasticizer, data=training, geom="histogram")
qplot(log(Superplasticizer)+1, data=training, geom="histogram")
qplot(Superplasticizer, data=training, geom="histogram")
qplot(log(Superplasticizer), data=training, geom="histogram")
log(0)
table(training$Superplasticizer)
log(0)+1
qplot(log(Superplasticizer+1), data=training, geom="histogram")
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(diagnosis)
table(diagnosis)
?grep
grep("IL",adData)
head(adData)
df[,grep("IL", names(df), value=TRUE)]
df[,grep("IL", names(adData), value=TRUE)]
df[,grep("^IL", names(adData), value=TRUE)]
grep("I",names(adData))
grep("I",names(adData), value=TRUE)
grep("IL",names(adData), value=TRUE)
adData[,grep("IL",names(adData), value=TRUE)]
?prcomp
prcomp(adData[,grep("IL",names(adData), value=TRUE)])
sdevi <- prcomp(adData[,grep("IL",names(adData), value=TRUE)])$sdev
sdevi
sdevi^2
vari <- sdevi^2
?quartile
cumsum(vari)
cumsum(vari)/sum(vari)
preProc <- preProcess(adData[,grep("IL",names(adData), value=TRUE)])
head(preProc)
sdevi <- preProc$std
vari <- sdevi^2
cumsum(vari)/sum(vari)
cumsum(devi)/sum(devi)
cumsum(sdevi)/sum(sdevi)
?preProcess
preProc <- preProcess(adData[,grep("IL",names(adData), value=TRUE)], method="pca", thresh=0.8)
preProc
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
predictors[,grep("IL",names(adData), value=TRUE)]
head(predictors[,grep("IL",names(adData), value=TRUE)])
head(predictors[,grep("^IL",names(adData), value=TRUE)])
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
#set thresh to 0.8 to retain 80% of variance by PCA
preProc <- preProcess(adData[,grep("^IL",names(adData), value=TRUE)], method="pca", thresh=0.8)
preProc
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors[,grep("^IL",names(adData), value=TRUE)])
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
preProc <- preProcess(training, method="pca")
trainPCA <- predict(preProc, training)
modelFitPCA <- train(training$diagnosis ~., method="glm", data=trainPCA)
predPCA <- predict(testing, modelFitPCA)
modelFitPCA
testPCA <- predict(preProc, testing)
predPCA <- predict(modelFitPCA, testPCA)
confusionMatrix(testing$diagnosis, predPCA)
modelFitNorm <- train(training$diagnosis ~., method="glm", data=training)
predNorm <- predict(modelFitNorm, testing)
confusionMatrix(testing$diagnosis, predNorm)
preProc
preProcess(training, method="PCA")
preProcess(training, method="pca")
preProcess(training[,-diagnosis], method="pca")
preProcess(training[,-c("diagnosis")], method="pca")
preProcess(training[,-"diagnosis"], method="pca")
preProcess(training[,-1], method="pca")
head(training)
trainPCA
head(trainPCA)
preProc <- preProcess(training, method="pca")
trainPCA <- predict(preProc, training)
head(trainPCA)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors[,grep("^IL",names(adData), value=TRUE)])
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
preProc <- preProcess(training[,-1], method="pca")
trainPCA <- predict(preProc, training[,-1])
modelFitPCA <- train(training$diagnosis ~., method="glm", data=trainPCA)
testPCA <- predict(preProc, testing[,-1])
predPCA <- predict(modelFitPCA, testPCA)
confusionMatrix(testing$diagnosis, predPCA)
modelFitNorm <- train(training$diagnosis ~., method="glm", data=training[,-1])
predNorm <- predict(modelFitNorm, testing[,-1])
confusionMatrix(testing$diagnosis, predNorm)
log(-10)
log(-2)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.7, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
set.seed(125)
modFit <- train(Case ~. , method="rpart", data=training)
print(modFit$finalModel)
head(testing)
print(modFit$finalModel)
modFit
plot(modFit$finalModel, uniform=TRUE, main="tree plot")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=0.8)
predict(modFit, newdata=testing)
[predict(modFit, newdata=testing) testing]
[predict(modFit, newdata=testing); testing]
data.frame(predict(modFit, newdata=testing), testing)
head(data.frame(predict(modFit, newdata=testing), testing))
result <- (data.frame(predict(modFit, newdata=testing), testing))
result[,c("TotalIntench2", " FiberWidthCh1", "PerimStatusCh1")]
names(result)
result[,c("predict.modFit..newdata...testing.","TotalIntench2", "FiberWidthCh1", "PerimStatusCh1")]
result[,c("TotalIntench2", "FiberWidthCh1", "PerimStatusCh1")]
result[,c("TotalIntenCh2", "FiberWidthCh1", "PerimStatusCh1")]
names(result)
result[,c("predict.modFit..newdata...testing.","TotalIntenCh2", "FiberWidthCh1", "PerimStatusCh1")]
head(segmentationOriginal$Cell)
head(segmentationOriginal)
training <- segmentationOriginal[segmentationOriginal$Case=="Train",] #segmentationOriginal[inTrain,]
testing <- segmentationOriginal[segmentationOriginal$Case=="Test",]#[-inTrain,]
set.seed(125)
modFit <- train(Class ~. , method="rpart", data=training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE, main="tree plot")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=0.8)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages('pgmm')
library(pgmm)
data(olive)
olive = olive[,-1]
head(olive)
modFit <- train(Area ~. , method="rpart", data=training)
predict(modFit, newdata = as.data.frame(t(colMeans(olive))))
modFit <- train(Area ~. , method="rpart", data=olive)
predict(modFit, newdata = as.data.frame(t(colMeans(olive))))
olive
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages('ElemStatLearn')
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
names(trainSA)
set.seed(13234)
modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl , method="glm", family="binomial", data=trainSA)
prediction <- predict(modFit, newdata = testSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
predicted <- predict(modFit, newdata = testSA)
head(predicted)
missClass(testSA$chd, predicted)
set.seed(13234)
modFit <- train(factor(chd) ~ age + alcohol + obesity + tobacco + typea + ldl , method="glm", family="binomial", data=trainSA)
predictedTrain <- predict(modFit, newdata = trainSA)
predictedTest <- predict(modFit, newdata = testSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, predictedTrain)
missClass(testSA$chd, predictedTest)
set.seed(13234)
modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl , method="glm", family="binomial", data=trainSA)
predictedTrain <- predict(modFit, newdata = trainSA)
predictedTest <- predict(modFit, newdata = testSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, predictedTrain)
missClass(testSA$chd, predictedTest)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
train <- vowel.train
test <- vowel.test
train$y <- factor(train$y)
test$y <- factor(test$y)
?varImp
set.seed(33833)
modFit <- train(y ~ . , method="rf", data=train)
#predictedTrain <- predict(modFit, newdata = trainSA)
#predictedTest <- predict(modFit, newdata = testSA)
varImp(modFit)
getwd()
setwd("/home/g/R/workDir/Assignment")
setwd("/home/g/R/workDir/Coursera08_ML/Assignment")
training <- read.table("./pml-training.csv", sep=",", header=TRUE)
testing <- read.table("./pml-testing.csv", sep=",", header=TRUE)
setwd("/home/g/R/workDir/Coursera08_ML/Assignment")
training <- read.table("./pml-training.csv", sep=",", header=TRUE)
testing <- read.table("./pml-testing.csv", sep=",", header=TRUE)
head(training)
summary(training)
head(testing)
testing <- read.table("./pml-testing.csv", sep=",", header=TRUE)
head(testing)
head(training)
dim(training)
dim(testing)
?sapply
?sumcols
?sumcol
?colsum
?colsums
?sum
is.na
?is.na
?colSums
sapply(training,2,colSums(is.na))
sapply(training,colSums(is.na))
sapply(training,colSums(is.na()))
sapply(training,function(x) colSums(is.na(x)))
apply(training,2,function(x) colSums(is.na(x)))
apply(training,2,function(x) sum(is.na(x)))
apply(training,2,function(x) sum(is.na(x))) == nrow(training)
dim(training)
sum(apply(training,2,function(x) sum(is.na(x))) )
badCols <- apply(training,2,function(x) sum(is.na(x))) > 15000)
training <- training[,-badCols]
sum(apply(training,2,function(x) sum(is.na(x))) )
badCols <- apply(training,2,function(x) sum(is.na(x))) > 15000
badCols
training <- training[,-badCols]
sum(apply(training,2,function(x) sum(is.na(x))) )
dim(training)
training <- read.table("./pml-training.csv", sep=",", header=TRUE)
badCols <- apply(training,2,function(x) sum(is.na(x))) > 15000
dim(training)
badCols
training <- training[,!badCols]
dim(training)
sum(apply(training,2,function(x) sum(is.na(x))) )
head(training[,1:15])
training <- training[,-1:7]
testing <- testing[,-1:7]
training <- training[,!1:7]
testing <- testing[,!1:7]
head(training[,1:15])
head(training)
setwd("/home/g/R/workDir/Coursera08_ML/Assignment")
training <- read.table("./pml-training.csv", sep=",", header=TRUE)
testing <- read.table("./pml-testing.csv", sep=",", header=TRUE)
badCols <- apply(training,2,function(x) sum(is.na(x))) > 15000
training <- training[,!badCols]
sum(apply(training,2,function(x) sum(is.na(x))) )
testing <- testing[,!badCols]
head(training[,1:7])
training <- training[,8:ncol(training)]
testing <- testing[,8:ncol(testing)]
head(training[,1:15])
head(training)
dim(training)
training$min_yaw_forearm
sum(is.na(training$min_yaw_forearm)
)
sum(is.missing(training$min_yaw_forearm))
summary(training$min_yaw_forearm)
summary(training$min_yaw_forearm == "")
training <- read.table("./pml-training.csv", sep=",", header=TRUE)
testing <- read.table("./pml-testing.csv", sep=",", header=TRUE)
badCols <- apply(training,2,function(x) (sum(is.na(x)) + sum(x==""))) > 15000
training <- training[,!badCols]
badCols
badCols <- apply(training,2,function(x) (sum(is.na(x)) + sum(x==""))) > 15000
badCols <- apply(training,2,function(x) ( sum(x==""))) > 15000
badCols
training$max_roll_forearm
training <- read.table("./pml-training.csv", sep=",", header=TRUE)
testing <- read.table("./pml-testing.csv", sep=",", header=TRUE)
badCols1 <- apply(training,2,function(x) (if(sum(is.na(x))>15000); return TRUE; else if(sum(is.na(x))==0 && sum(x=="")>15000); return TRUE; else return FALSE))
badCols1 <- apply(training,2,function(x) (if(sum(is.na(x))>15000){ return TRUE} else if(sum(is.na(x))==0 && sum(x=="")>15000){return TRUE} else{return FALSE} ))
badCols <- apply(training,2,function(x) ( sum(is.na(x)))) > 15000
badCols
training <- training[,!badCols]
testing <- testing[,!badCols]
badCols <- apply(training,2,function(x) ( sum(x==""))) > 15000
badCols
training <- training[,!badCols]
testing <- testing[,!badCols]
sum(apply(training,2,function(x) (sum(is.na(x)) + sum(x==""))) )
dim(training)
head(data[,1:7])
data <- data[,8:ncol(data)]
setwd("/home/g/R/workDir/Coursera08_ML/Assignment")
data <- read.table("./pml-training.csv", sep=",", header=TRUE)
dim(data)
summary(data$classe)
badCols <- apply(data,2,function(x) ( sum(is.na(x)))) > 15000
data <- data[,!badCols]
badCols <- apply(data,2,function(x) ( sum(x==""))) > 15000
data <- data[,!badCols]
sum(apply(data,2,function(x) (sum(is.na(x)) + sum(x==""))) )
head(data[,1:7])
data <- data[,8:ncol(data)]
inTrain <- createDataPartition(y=data$classe, p=0.7, list=FALSE)
training <- data[inTrain,]
testing <- data[-inTrain,]
modelFit <- train(classe ~., method="rf", data=training, trControl = trainControl(method="repeatedcv", number=5, repeats=5))
modelFit
